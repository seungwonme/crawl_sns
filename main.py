"""
@file main.py
@description SNS í¬ë¡¤ë§ CLI ì¸í„°í˜ì´ìŠ¤

ì´ ëª¨ë“ˆì€ ì—¬ëŸ¬ SNS í”Œë«í¼ì˜ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•˜ê¸° ìœ„í•œ ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. í”Œë«í¼ë³„ í¬ë¡¤ë§ ëª…ë ¹ì–´ (threads, linkedin, x, etc.)
2. í¬ë¡¤ë§ ì˜µì…˜ ì„¤ì • (ê²Œì‹œê¸€ ìˆ˜, ì €ì¥ ìœ„ì¹˜)
3. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥

í•µì‹¬ êµ¬í˜„ ë¡œì§:
- Typerë¥¼ ì‚¬ìš©í•œ ì§ê´€ì ì¸ CLI ì¸í„°í˜ì´ìŠ¤
- Playwrightë¥¼ ì‚¬ìš©í•œ ë¸Œë¼ìš°ì € ìë™í™” í¬ë¡¤ë§
- ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ìë™ ì €ì¥

@dependencies
- typer: CLI í”„ë ˆì„ì›Œí¬
- playwright: ë¸Œë¼ìš°ì € ìë™í™”
- asyncio: ë¹„ë™ê¸° ì²˜ë¦¬
- datetime: íŒŒì¼ëª… ìƒì„±ìš©
- json: ë°ì´í„° ì§ë ¬í™”
- pydantic: ë°ì´í„° ëª¨ë¸ë§
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional

import typer
from playwright.async_api import async_playwright
from pydantic import BaseModel

# === Version ===
__version__ = "0.1.0"


# === Data Models ===
class Post(BaseModel):
    """SNS ê²Œì‹œê¸€ ë°ì´í„° ëª¨ë¸"""

    platform: str
    author: str
    content: str
    timestamp: str
    url: Optional[str] = None
    likes: Optional[int] = None
    comments: Optional[int] = None
    shares: Optional[int] = None

    class Config:
        extra = "allow"  # í”Œë«í¼ë³„ ì¶”ê°€ í•„ë“œ í—ˆìš©


# === Core Functions ===
def save_posts_to_file(posts: List[Post], filepath: str) -> None:
    """ê²Œì‹œê¸€ ëª©ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    output_data = {
        "metadata": {
            "total_posts": len(posts),
            "crawled_at": datetime.now().isoformat(),
            "platform": posts[0].platform if posts else "unknown",
        },
        "posts": [post.model_dump() for post in posts],
    }

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)


# === Platform Crawlers ===
async def crawl_threads(count: int = 5) -> List[Post]:
    """
    Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ Threadsì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    """
    posts = []

    try:
        typer.echo(f"ğŸ§µ Threads í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

        async with async_playwright() as p:
            # ë¸Œë¼ìš°ì € ì‹¤í–‰
            browser = await p.chromium.launch(headless=False)

            # User-Agentë¥¼ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1"
            )

            page = await context.new_page()

            # Threads ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™
            await page.goto("https://threads.net", wait_until="networkidle")
            typer.echo(f"âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ")

            # í˜ì´ì§€ ë¡œë“œ ì¶”ê°€ ëŒ€ê¸° (3ì´ˆ)
            await page.wait_for_timeout(3000)

            # DOM êµ¬ì¡° ë¶„ì„ì— ë”°ë¥¸ ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            # Column body ì˜ì—­ ë‚´ì˜ ê²Œì‹œê¸€ë“¤ì„ ì°¾ê¸°
            column_body = await page.query_selector(
                '[data-pressable-container="true"], [aria-label="Column body"], region[role] >> text=Column body'
            )

            if not column_body:
                # ëŒ€ì•ˆ: í™ˆ í”¼ë“œ ì˜ì—­ ì°¾ê¸°
                column_body = await page.query_selector('div[style*="flex"]')

            post_elements = []
            if column_body:
                # Column body ë‚´ì˜ ì§ì ‘ì ì¸ ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆë“¤ ì°¾ê¸°
                post_elements = await column_body.query_selector_all(
                    'div[style*="cursor: pointer"] >> xpath=..'
                )

            # ë§Œì•½ ìœ„ì˜ ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
            if not post_elements:
                # ê²Œì‹œê¸€ ë§í¬ íŒ¨í„´ì„ ì´ìš©í•´ ì°¾ê¸°
                post_links = await page.query_selector_all('a[href*="/@"][href*="/post/"]')
                typer.echo(f"ğŸ”— {len(post_links)}ê°œì˜ ê²Œì‹œê¸€ ë§í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")

                # ê° ë§í¬ì˜ ìµœìƒìœ„ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
                containers = []
                for link in post_links[: count * 2]:  # ì—¬ìœ ìˆê²Œ ë” ë§ì´ ìˆ˜ì§‘
                    try:
                        # ìƒìœ„ 4ë‹¨ê³„ê¹Œì§€ ì˜¬ë¼ê°€ì„œ ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
                        container = await link.evaluate_handle(
                            """(element) => {
                            let current = element;
                            for (let i = 0; i < 6; i++) {
                                if (current.parentElement) {
                                    current = current.parentElement;
                                    // ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆë¡œ ë³´ì´ëŠ” ì¡°ê±´ë“¤
                                    if (current.querySelector('a[href*="/@"]') &&
                                        current.querySelector('time') &&
                                        current.textContent && current.textContent.length > 20) {
                                        return current;
                                    }
                                }
                            }
                            return null;
                        }"""
                        )

                        if container:
                            element = container.as_element()
                            if element and element not in containers:
                                containers.append(element)

                    except Exception as e:
                        continue

                post_elements = containers[:count]

            typer.echo(f"ğŸ” {len(post_elements)}ê°œì˜ ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")

            # ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ
            for i, element in enumerate(post_elements[:count]):
                try:
                    # ì‘ì„±ì ì •ë³´ ì¶”ì¶œ - ë” ì •í™•í•œ ì„ íƒì ì‚¬ìš©
                    author_link = await element.query_selector(
                        'a[href^="/@"]:not([href*="/post/"])'
                    )
                    author = "Unknown"
                    if author_link:
                        href = await author_link.get_attribute("href")
                        if href and href.startswith("/@"):
                            author = href.replace("/@", "").split("/")[0]

                    # ê²Œì‹œê¸€ URL ì¶”ì¶œ
                    post_url_element = await element.query_selector('a[href*="/post/"]')
                    post_url = None
                    if post_url_element:
                        href = await post_url_element.get_attribute("href")
                        if href:
                            post_url = (
                                f"https://threads.net{href}"
                                if not href.startswith("http")
                                else href
                            )

                    # ê²Œì‹œ ì‹œê°„ ì¶”ì¶œ
                    time_element = await element.query_selector("time")
                    timestamp = "ì•Œ ìˆ˜ ì—†ìŒ"
                    if time_element:
                        time_text = await time_element.inner_text()
                        if time_text:
                            timestamp = time_text.strip()

                    # ì½˜í…ì¸  ì¶”ì¶œ - ì‹¤ì œ DOM êµ¬ì¡°ì— ë§ì¶° ê°œì„ 
                    content_text = ""

                    # ë°©ë²• 1: í…ìŠ¤íŠ¸ê°€ ë§ì€ div ìš”ì†Œë“¤ ì°¾ê¸°
                    content_divs = await element.query_selector_all("div")
                    content_texts = []

                    for div in content_divs:
                        try:
                            text = await div.inner_text()
                            if text and len(text.strip()) > 15:  # ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸ë§Œ
                                # ì‘ì„±ìëª…, ì‹œê°„, ë²„íŠ¼ í…ìŠ¤íŠ¸ ë“± ì œì™¸
                                if not any(
                                    exclude in text.lower()
                                    for exclude in [
                                        "like",
                                        "comment",
                                        "repost",
                                        "share",
                                        "more",
                                        "translate",
                                        "ago",
                                        author.lower() if author != "Unknown" else "",
                                    ]
                                ):
                                    content_texts.append(text.strip())
                        except:
                            continue

                    # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë©”ì¸ ì½˜í…ì¸ ë¡œ ì„ íƒ
                    if content_texts:
                        content_text = max(content_texts, key=len)

                    # ë°©ë²• 2: ë§Œì•½ ìœ„ì—ì„œ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
                    if not content_text or len(content_text) < 20:
                        full_text = await element.inner_text()
                        if full_text:
                            lines = full_text.split("\n")
                            for line in lines:
                                line = line.strip()
                                if (
                                    len(line) > 20
                                    and not any(
                                        exclude in line.lower()
                                        for exclude in [
                                            "like",
                                            "comment",
                                            "repost",
                                            "share",
                                            "more",
                                            "ago",
                                        ]
                                    )
                                    and not line.isdigit()
                                ):
                                    content_text = line
                                    break

                    # ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ - ì‹¤ì œ ë²„íŠ¼ í…ìŠ¤íŠ¸ ë¶„ì„
                    likes = 0
                    comments = 0
                    reposts = 0
                    shares = 0

                    # Like ë²„íŠ¼ ì°¾ê¸°
                    like_buttons = await element.query_selector_all('button:has-text("Like")')
                    for btn in like_buttons:
                        try:
                            text = await btn.inner_text()
                            # "Like 201" íŒ¨í„´ì—ì„œ ìˆ«ì ì¶”ì¶œ
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                likes = int(numbers)
                        except:
                            pass

                    # Comment ë²„íŠ¼ ì°¾ê¸°
                    comment_buttons = await element.query_selector_all('button:has-text("Comment")')
                    for btn in comment_buttons:
                        try:
                            text = await btn.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                comments = int(numbers)
                        except:
                            pass

                    # Repost ë²„íŠ¼ ì°¾ê¸°
                    repost_buttons = await element.query_selector_all('button:has-text("Repost")')
                    for btn in repost_buttons:
                        try:
                            text = await btn.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                reposts = int(numbers)
                        except:
                            pass

                    # Share ë²„íŠ¼ ì°¾ê¸°
                    share_buttons = await element.query_selector_all('button:has-text("Share")')
                    for btn in share_buttons:
                        try:
                            text = await btn.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                shares = int(numbers)
                        except:
                            pass

                    # ìœ íš¨í•œ ê²Œì‹œê¸€ì¸ì§€ í™•ì¸ - ì¡°ê±´ ì™„í™”
                    if content_text and len(content_text.strip()) > 10 and author != "Unknown":
                        post = Post(
                            platform="threads",
                            author=author,
                            content=content_text[:500],  # ê¸¸ì´ ì œí•œ
                            timestamp=timestamp,
                            url=post_url,
                            likes=likes if likes > 0 else None,
                            comments=comments if comments > 0 else None,
                            shares=shares if shares > 0 else None,
                        )
                        posts.append(post)
                        typer.echo(f"   âœ… ê²Œì‹œê¸€ {len(posts)}: @{author} - {content_text[:50]}...")
                    else:
                        typer.echo(
                            f"   âš ï¸  ê²Œì‹œê¸€ {i+1}: ë°ì´í„° ë¶€ì¡± - author={author}, content_len={len(content_text) if content_text else 0}"
                        )

                except Exception as e:
                    typer.echo(f"   âŒ ê²Œì‹œê¸€ {i+1} íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

            await browser.close()
            typer.echo(f"ğŸ“Š ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

            # ë§Œì•½ ì¶”ì¶œëœ ê²Œì‹œê¸€ì´ ì—†ë‹¤ë©´ ë””ë²„ê·¸ ì •ë³´ ì œê³µ
            if not posts:
                typer.echo(f"âŒ ê²Œì‹œê¸€ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                typer.echo(f"ğŸ’¡ íŒíŠ¸: ThreadsëŠ” ë¡œê·¸ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                typer.echo(
                    f"ğŸ’¡ í˜„ì¬ {len(post_elements)}ê°œì˜ ìš”ì†Œë¥¼ ë¶„ì„í–ˆì§€ë§Œ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )

    except Exception as e:
        typer.echo(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return posts


async def crawl_linkedin(count: int = 5) -> List[Post]:
    """LinkedInì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    posts = []

    try:
        typer.echo(f"ğŸ’¼ LinkedIn í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

        async with async_playwright() as p:
            # ë¸Œë¼ìš°ì € ì‹¤í–‰
            browser = await p.chromium.launch(headless=False)

            # User-Agentë¥¼ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )

            page = await context.new_page()

            # LinkedIn í”¼ë“œ í˜ì´ì§€ë¡œ ì´ë™
            await page.goto("https://www.linkedin.com/feed/", wait_until="networkidle")
            typer.echo(f"âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ")

            # í˜ì´ì§€ ë¡œë“œ ì¶”ê°€ ëŒ€ê¸°
            await page.wait_for_timeout(3000)

            # LinkedInì€ ë¡œê·¸ì¸ì´ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
            if await page.query_selector('input[name="session_key"]'):
                typer.echo(f"âš ï¸  LinkedInì€ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ê³µê°œ ê²Œì‹œê¸€ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                await page.goto("https://www.linkedin.com/posts/", wait_until="networkidle")
                await page.wait_for_timeout(2000)

            # ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            post_elements = await page.query_selector_all(
                "div[data-id], article, .feed-shared-update-v2, .occludable-update"
            )

            # ëŒ€ì•ˆ ë°©ë²•: ë” ì¼ë°˜ì ì¸ ì„ íƒì ì‚¬ìš©
            if not post_elements:
                post_elements = await page.query_selector_all(
                    'div:has(a[href*="/posts/"]), div:has(a[href*="/activity-"])'
                )

            typer.echo(f"ğŸ” {len(post_elements)}ê°œì˜ ê²Œì‹œê¸€ ìš”ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")

            # ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ
            for i, element in enumerate(post_elements[:count]):
                try:
                    # ì‘ì„±ì ì •ë³´ ì¶”ì¶œ
                    author_link = await element.query_selector(
                        'a[href*="/in/"], a[href*="/company/"]'
                    )
                    author = "Unknown"
                    if author_link:
                        text = await author_link.inner_text()
                        if text and text.strip():
                            author = text.strip().split("\n")[0]

                    # ê²Œì‹œê¸€ URL ì¶”ì¶œ
                    post_link = await element.query_selector(
                        'a[href*="/posts/"], a[href*="/activity-"]'
                    )
                    post_url = None
                    if post_link:
                        href = await post_link.get_attribute("href")
                        if href:
                            post_url = (
                                f"https://www.linkedin.com{href}"
                                if not href.startswith("http")
                                else href
                            )

                    # ê²Œì‹œ ì‹œê°„ ì¶”ì¶œ
                    time_element = await element.query_selector(
                        'time, span:has-text("ago"), span:has-text("ì¼"), span:has-text("ì‹œê°„")'
                    )
                    timestamp = "ì•Œ ìˆ˜ ì—†ìŒ"
                    if time_element:
                        time_text = await time_element.inner_text()
                        if time_text:
                            timestamp = time_text.strip()

                    # ì½˜í…ì¸  ì¶”ì¶œ
                    content_text = ""

                    # LinkedIn ê²Œì‹œê¸€ ì½˜í…ì¸  ì„ íƒìë“¤
                    content_selectors = [
                        ".feed-shared-text",
                        ".feed-shared-inline-show-more-text",
                        'div[data-test-id="main-feed-activity-card"] span[dir="ltr"]',
                        ".break-words span",
                    ]

                    for selector in content_selectors:
                        content_element = await element.query_selector(selector)
                        if content_element:
                            text = await content_element.inner_text()
                            if text and len(text.strip()) > 20:
                                content_text = text.strip()
                                break

                    # ëŒ€ì•ˆ: ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
                    if not content_text:
                        full_text = await element.inner_text()
                        if full_text:
                            lines = full_text.split("\n")
                            for line in lines:
                                line = line.strip()
                                if (
                                    len(line) > 30
                                    and not any(
                                        exclude in line.lower()
                                        for exclude in [
                                            "like",
                                            "comment",
                                            "share",
                                            "repost",
                                            "follow",
                                            "connection",
                                        ]
                                    )
                                    and not line.isdigit()
                                ):
                                    content_text = line
                                    break

                    # ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ
                    likes = 0
                    comments = 0

                    # ì¢‹ì•„ìš” ìˆ˜ (LinkedInì€ ë‹¤ì–‘í•œ ë¦¬ì•¡ì…˜ í¬í•¨)
                    reaction_elements = await element.query_selector_all(
                        'button:has-text("reaction"), span:has-text("reaction"), .social-action'
                    )
                    for elem in reaction_elements:
                        try:
                            text = await elem.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                likes = int(numbers)
                                break
                        except:
                            pass

                    # ëŒ“ê¸€ ìˆ˜
                    comment_elements = await element.query_selector_all(
                        'button:has-text("comment"), span:has-text("comment")'
                    )
                    for elem in comment_elements:
                        try:
                            text = await elem.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                comments = int(numbers)
                                break
                        except:
                            pass

                    # ìœ íš¨í•œ ê²Œì‹œê¸€ì¸ì§€ í™•ì¸
                    if content_text and len(content_text.strip()) > 15 and author != "Unknown":
                        post = Post(
                            platform="linkedin",
                            author=author,
                            content=content_text[:500],
                            timestamp=timestamp,
                            url=post_url,
                            likes=likes if likes > 0 else None,
                            comments=comments if comments > 0 else None,
                            shares=None,
                        )
                        posts.append(post)
                        typer.echo(f"   âœ… ê²Œì‹œê¸€ {len(posts)}: {author} - {content_text[:50]}...")
                    else:
                        typer.echo(
                            f"   âš ï¸  ê²Œì‹œê¸€ {i+1}: ë°ì´í„° ë¶€ì¡± - author={author}, content_len={len(content_text) if content_text else 0}"
                        )

                except Exception as e:
                    typer.echo(f"   âŒ ê²Œì‹œê¸€ {i+1} íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

            await browser.close()
            typer.echo(f"ğŸ“Š ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

            if not posts:
                typer.echo(f"âŒ ê²Œì‹œê¸€ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                typer.echo(f"ğŸ’¡ íŒíŠ¸: LinkedInì€ ë¡œê·¸ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        typer.echo(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return posts


async def crawl_x(count: int = 5) -> List[Post]:
    """X (Twitter) í¬ë¡¤ë§ (êµ¬í˜„ ì˜ˆì •)"""
    typer.echo(f"ğŸ¦ X í¬ë¡¤ë§ êµ¬í˜„ ì˜ˆì •")
    return []


async def crawl_geeknews(count: int = 5) -> List[Post]:
    """GeekNewsì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    posts = []

    try:
        typer.echo(f"ğŸ¤“ GeekNews í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

        async with async_playwright() as p:
            # ë¸Œë¼ìš°ì € ì‹¤í–‰
            browser = await p.chromium.launch(headless=False)

            # User-Agentë¥¼ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )

            page = await context.new_page()

            # GeekNews ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™
            await page.goto("https://news.hada.io/", wait_until="networkidle")
            typer.echo(f"âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ")

            # í˜ì´ì§€ ë¡œë“œ ì¶”ê°€ ëŒ€ê¸°
            await page.wait_for_timeout(2000)

            # GeekNews ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            post_elements = await page.query_selector_all(
                ".topic_row, .article-item, .news-item, .post-item"
            )

            # ëŒ€ì•ˆ: ë§í¬ ê¸°ë°˜ìœ¼ë¡œ ì°¾ê¸°
            if not post_elements:
                post_elements = await page.query_selector_all('div:has(a[href*="/topic/"])')

            # ë” ì¼ë°˜ì ì¸ ë°©ë²•: ì œëª©ì´ ìˆëŠ” ìš”ì†Œë“¤
            if not post_elements:
                title_links = await page.query_selector_all('a[href*="/topic/"]')
                containers = []
                for link in title_links[: count * 2]:
                    try:
                        # ìƒìœ„ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
                        container = await link.evaluate_handle(
                            """(element) => {
                            let current = element;
                            for (let i = 0; i < 4; i++) {
                                if (current.parentElement) {
                                    current = current.parentElement;
                                    if (current.textContent && current.textContent.length > 50) {
                                        return current;
                                    }
                                }
                            }
                            return null;
                        }"""
                        )

                        if container:
                            element = container.as_element()
                            if element and element not in containers:
                                containers.append(element)

                    except Exception:
                        continue

                post_elements = containers[:count]

            typer.echo(f"ğŸ” {len(post_elements)}ê°œì˜ ê²Œì‹œê¸€ ìš”ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")

            # ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ
            for i, element in enumerate(post_elements[:count]):
                try:
                    # ì œëª©/ì½˜í…ì¸  ì¶”ì¶œ (GeekNewsëŠ” ì œëª©ì´ ì£¼ìš” ì½˜í…ì¸ )
                    title_link = await element.query_selector('a[href*="/topic/"]')
                    content_text = ""
                    post_url = None

                    if title_link:
                        content_text = await title_link.inner_text()
                        href = await title_link.get_attribute("href")
                        if href:
                            post_url = (
                                f"https://news.hada.io{href}"
                                if not href.startswith("http")
                                else href
                            )

                    # ì‘ì„±ì ì •ë³´ ì¶”ì¶œ (GeekNewsëŠ” ë³´í†µ ì‘ì„±ìê°€ ëª…ì‹œë˜ì§€ ì•ŠìŒ)
                    author = "GeekNews"
                    author_element = await element.query_selector(".author, .user, .by")
                    if author_element:
                        author_text = await author_element.inner_text()
                        if author_text and author_text.strip():
                            author = author_text.strip()

                    # ê²Œì‹œ ì‹œê°„ ì¶”ì¶œ
                    time_element = await element.query_selector(
                        'time, .time, .date, span:has-text("ì‹œê°„"), span:has-text("ì¼"), span:has-text("ago")'
                    )
                    timestamp = "ì•Œ ìˆ˜ ì—†ìŒ"
                    if time_element:
                        time_text = await time_element.inner_text()
                        if time_text:
                            timestamp = time_text.strip()

                    # ëŒ“ê¸€ ìˆ˜ë‚˜ ì ìˆ˜ ì¶”ì¶œ
                    comments = 0
                    likes = 0

                    # ëŒ“ê¸€ ìˆ˜ ì°¾ê¸°
                    comment_elements = await element.query_selector_all(
                        'span:has-text("ëŒ“ê¸€"), .comment, a[href*="#comment"]'
                    )
                    for elem in comment_elements:
                        try:
                            text = await elem.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                comments = int(numbers)
                                break
                        except:
                            pass

                    # ì ìˆ˜ë‚˜ ì¶”ì²œ ìˆ˜ ì°¾ê¸°
                    score_elements = await element.query_selector_all(".score, .points, .vote")
                    for elem in score_elements:
                        try:
                            text = await elem.inner_text()
                            numbers = "".join(filter(str.isdigit, text))
                            if numbers:
                                likes = int(numbers)
                                break
                        except:
                            pass

                    # ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ìš”ì•½ ì¶”ì¶œ
                    description_element = await element.query_selector(
                        ".description, .summary, .excerpt"
                    )
                    if description_element:
                        desc_text = await description_element.inner_text()
                        if desc_text and len(desc_text.strip()) > 10:
                            content_text += f"\n{desc_text.strip()}"

                    # ìœ íš¨í•œ ê²Œì‹œê¸€ì¸ì§€ í™•ì¸
                    if content_text and len(content_text.strip()) > 10:
                        post = Post(
                            platform="geeknews",
                            author=author,
                            content=content_text.strip()[:500],
                            timestamp=timestamp,
                            url=post_url,
                            likes=likes if likes > 0 else None,
                            comments=comments if comments > 0 else None,
                            shares=None,
                        )
                        posts.append(post)
                        typer.echo(f"   âœ… ê²Œì‹œê¸€ {len(posts)}: {author} - {content_text[:50]}...")
                    else:
                        typer.echo(
                            f"   âš ï¸  ê²Œì‹œê¸€ {i+1}: ë°ì´í„° ë¶€ì¡± - content_len={len(content_text) if content_text else 0}"
                        )

                except Exception as e:
                    typer.echo(f"   âŒ ê²Œì‹œê¸€ {i+1} íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

            await browser.close()
            typer.echo(f"ğŸ“Š ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

            if not posts:
                typer.echo(f"âŒ ê²Œì‹œê¸€ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                typer.echo(f"ğŸ’¡ GeekNews ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        typer.echo(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return posts


async def crawl_reddit(count: int = 5) -> List[Post]:
    """Reddit í¬ë¡¤ë§ (êµ¬í˜„ ì˜ˆì •)"""
    typer.echo(f"ğŸ”¸ Reddit í¬ë¡¤ë§ êµ¬í˜„ ì˜ˆì •")
    return []


# === CLI Interface ===
app = typer.Typer(
    name="crawl-sns",
    help="SNS í”Œë«í¼(Threads, LinkedIn, X, GeekNews, Reddit) í¬ë¡¤ë§ ë„êµ¬",
    add_completion=False,
)


@app.command()
def threads(
    count: int = typer.Option(5, "--count", "-c", help="ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜"),
    output: Optional[str] = typer.Option(
        None, "--output", "-o", help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: ìë™ ìƒì„±)"
    ),
):
    """
    Threadsì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
    python main.py threads --count 10
    python main.py threads -c 3 -o my_threads.json
    """
    typer.echo(f"ğŸ§µ Threads í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
    posts = asyncio.run(crawl_threads(count))

    if not posts:
        typer.echo("âŒ í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        raise typer.Exit(1)

    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    if not output:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output = f"data/threads_{timestamp}.json"

    # data ë””ë ‰í† ë¦¬ ìƒì„±
    Path("data").mkdir(exist_ok=True)

    # ê²°ê³¼ ì €ì¥
    save_posts_to_file(posts, output)

    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    typer.echo(f"\nğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ ìš”ì•½:")
    typer.echo(f"   - í”Œë«í¼: Threads")
    typer.echo(f"   - ìˆ˜ì§‘ëœ ê²Œì‹œê¸€: {len(posts)}ê°œ")
    typer.echo(f"   - ì €ì¥ ìœ„ì¹˜: {output}")

    # ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ë¯¸ë¦¬ë³´ê¸°
    if posts:
        first_post = posts[0]
        typer.echo(f"\nğŸ“„ ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ë¯¸ë¦¬ë³´ê¸°:")
        typer.echo(f"   ì‘ì„±ì: {first_post.author}")
        typer.echo(f"   ë‚´ìš©: {first_post.content[:100]}...")
        typer.echo(f"   ì‹œê°„: {first_post.timestamp}")


@app.command()
def linkedin(
    count: int = typer.Option(5, "--count", "-c", help="ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜"),
    output: Optional[str] = typer.Option(
        None, "--output", "-o", help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: ìë™ ìƒì„±)"
    ),
):
    """
    LinkedInì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
    python main.py linkedin --count 10
    python main.py linkedin -c 3 -o my_linkedin.json
    """
    typer.echo(f"ğŸ’¼ LinkedIn í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
    posts = asyncio.run(crawl_linkedin(count))

    if not posts:
        typer.echo("âŒ í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        raise typer.Exit(1)

    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    if not output:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output = f"data/linkedin_{timestamp}.json"

    # data ë””ë ‰í† ë¦¬ ìƒì„±
    Path("data").mkdir(exist_ok=True)

    # ê²°ê³¼ ì €ì¥
    save_posts_to_file(posts, output)

    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    typer.echo(f"\nğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ ìš”ì•½:")
    typer.echo(f"   - í”Œë«í¼: LinkedIn")
    typer.echo(f"   - ìˆ˜ì§‘ëœ ê²Œì‹œê¸€: {len(posts)}ê°œ")
    typer.echo(f"   - ì €ì¥ ìœ„ì¹˜: {output}")

    # ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ë¯¸ë¦¬ë³´ê¸°
    if posts:
        first_post = posts[0]
        typer.echo(f"\nğŸ“„ ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ë¯¸ë¦¬ë³´ê¸°:")
        typer.echo(f"   ì‘ì„±ì: {first_post.author}")
        typer.echo(f"   ë‚´ìš©: {first_post.content[:100]}...")
        typer.echo(f"   ì‹œê°„: {first_post.timestamp}")


@app.command()
def version():
    """ë²„ì „ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    typer.echo("SNS Crawler v0.1.0")
    typer.echo("Playwright ê¸°ë°˜ í¬ë¡¤ë§ ë„êµ¬")


@app.command()
def status():
    """í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    typer.echo("ğŸ“‹ SNS Crawler ìƒíƒœ:")
    typer.echo("   âœ… Threads í¬ë¡¤ëŸ¬ - êµ¬í˜„ ì™„ë£Œ (Playwright ê¸°ë°˜)")
    typer.echo("   ğŸ”§ LinkedIn í¬ë¡¤ëŸ¬ - êµ¬í˜„ ì™„ë£Œ (í…ŒìŠ¤íŠ¸ í•„ìš”)")
    typer.echo("   ğŸ”§ GeekNews í¬ë¡¤ëŸ¬ - êµ¬í˜„ ì™„ë£Œ (í…ŒìŠ¤íŠ¸ í•„ìš”)")
    typer.echo("   â³ X í¬ë¡¤ëŸ¬ - ê°œë°œ ì˜ˆì •")
    typer.echo("   â³ Reddit í¬ë¡¤ëŸ¬ - ê°œë°œ ì˜ˆì •")


if __name__ == "__main__":
    app()

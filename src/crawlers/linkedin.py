"""
@file linkedin.py
@description LinkedIn í”Œë«í¼ ì „ìš© í¬ë¡¤ëŸ¬

ì´ ëª¨ë“ˆì€ LinkedIn í”Œë«í¼ì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. LinkedIn í”¼ë“œì—ì„œ ê²Œì‹œê¸€ ìˆ˜ì§‘
2. LinkedIn ê³„ì •ì„ í†µí•œ ë¡œê·¸ì¸ ì§€ì›
3. ì‘ì„±ì, ì½˜í…ì¸ , ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ
4. ì„¸ì…˜ ê´€ë¦¬ (ì¬ë¡œê·¸ì¸ ë°©ì§€)
5. ì ì§„ì  ì¶”ì¶œ ì‹œìŠ¤í…œ (ìŠ¤í¬ë¡¤ë§, ë‹¤ì¤‘ ì„ íƒì)

í•µì‹¬ êµ¬í˜„ ë¡œì§:
- LinkedIn ë¡œê·¸ì¸ì„ í†µí•œ í”¼ë“œ ì ‘ê·¼
- ì ì§„ì  ìŠ¤í¬ë¡¤ë§ìœ¼ë¡œ ë” ë§ì€ ê²Œì‹œê¸€ ë¡œë“œ
- ë‹¤ì¤‘ ì„ íƒì ì‹œìŠ¤í…œìœ¼ë¡œ ê°•ê±´í•œ DOM ì¶”ì¶œ
- ë‹¨ê³„ë³„ ì¶”ì¶œ ë° ê²€ì¦

@dependencies
- playwright.async_api: ë¸Œë¼ìš°ì € ìë™í™”
- typer: CLI ì¶œë ¥
- .base: ë² ì´ìŠ¤ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤

@see {@link https://linkedin.com} - LinkedIn í”Œë«í¼
"""

import json
import os
import random
from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
from dotenv import load_dotenv
from playwright.async_api import Page
from playwright.async_api import TimeoutError as PlaywrightTimeoutError

from ..models import Post
from .base import BaseCrawler

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class LinkedInCrawler(BaseCrawler):
    """
    LinkedIn í”Œë«í¼ ì „ìš© í¬ë¡¤ëŸ¬

    LinkedInì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ê³„ì • ë¡œê·¸ì¸ì„ í†µí•´ í”¼ë“œì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    Features:
    - Storage State ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬ (ì¬ë¡œê·¸ì¸ ë°©ì§€)
    - í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ë³´ì•ˆ ê³„ì • ê´€ë¦¬
    - ì ì§„ì  ìŠ¤í¬ë¡¤ë§ ë° ì¶”ì¶œ ì‹œìŠ¤í…œ
    - ë‹¤ì¤‘ ì„ íƒì ê¸°ë°˜ ê°•ê±´í•œ DOM íŒŒì‹±
    - ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ ì‹œë®¬ë ˆì´ì…˜
    - ê°•ê±´í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
    """

    def __init__(self, debug_mode: bool = False):
        super().__init__(
            platform_name="LinkedIn",
            base_url="https://www.linkedin.com/feed/",
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            debug_mode=debug_mode,
        )

        # í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •
        self.username = os.getenv("LINKEDIN_USERNAME")
        self.password = os.getenv("LINKEDIN_PASSWORD")
        self.session_path = Path(os.getenv("LINKEDIN_SESSION_PATH", "./data/linkedin_session.json"))
        self.login_timeout = int(os.getenv("LINKEDIN_LOGIN_TIMEOUT", "30000"))
        self.login_retry_count = int(os.getenv("LINKEDIN_LOGIN_RETRY_COUNT", "3"))

        # ì ì§„ì  ì¶”ì¶œ ì„¤ì •
        self.max_scroll_attempts = 5
        self.scroll_delay = 2000

        # ìƒíƒœ ê´€ë¦¬
        self.is_logged_in = False

        # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
        self.session_path.parent.mkdir(parents=True, exist_ok=True)

    async def _crawl_implementation(self, page: Page, count: int) -> List[Post]:
        """
        LinkedIn í”Œë«í¼ì—ì„œ ê²Œì‹œê¸€ í¬ë¡¤ë§ ì‹¤í–‰ - ê°œì„ ëœ ë²„ì „
        """
        posts = []

        # ê¸°ì¡´ ì„¸ì…˜ ë¡œë“œ ì‹œë„ (ê°œì„ ëœ ë°©ì‹)
        await self._load_session(page)

        # ì„¸ì…˜ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì§ì ‘ í˜ì´ì§€ ë¡œë“œ ì‹œë„
        if not self.is_logged_in:
            typer.echo("ğŸŒ ìƒˆë¡œìš´ ì„¸ì…˜ìœ¼ë¡œ í˜ì´ì§€ ì ‘ê·¼ ì¤‘...")

            # ë‹¨ê³„ì  í˜ì´ì§€ ë¡œë“œ
            if not await self._gradual_page_load(page):
                typer.echo("âŒ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨")
                return posts

            # ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
            if await self._verify_login_status(page):
                typer.echo("âœ… ì´ë¯¸ ë¡œê·¸ì¸ëœ ìƒíƒœì…ë‹ˆë‹¤")
                self.is_logged_in = True
            else:
                # ë¡œê·¸ì¸ ì‹œë„
                await self._attempt_login(page)

        # ì¶”ê°€ ì•ˆì •í™” ëŒ€ê¸°
        await page.wait_for_timeout(3000)

        # ì ì§„ì  ê²Œì‹œê¸€ ìˆ˜ì§‘
        posts = await self._progressive_post_collection(page, count)

        return posts

    async def _progressive_post_collection(self, page: Page, target_count: int) -> List[Post]:
        """ê°œì„ ëœ ì ì§„ì  ê²Œì‹œê¸€ ìˆ˜ì§‘ ì‹œìŠ¤í…œ"""
        posts = []
        scroll_attempts = 0

        typer.echo(f"ğŸ”„ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì‹œì‘ (ëª©í‘œ: {target_count}ê°œ)")

        while len(posts) < target_count and scroll_attempts < self.max_scroll_attempts:
            # 1ë‹¨ê³„: í˜ì´ì§€ ì „ì²´ì˜ ë”ë³´ê¸° ë²„íŠ¼ ëª¨ë‘ í´ë¦­
            await self._expand_all_posts_on_page(page)

            # 2ë‹¨ê³„: ìƒë‹¨ì—ì„œë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ê²Œì‹œê¸€ ì¶”ì¶œ
            current_posts = await self._collect_expanded_posts(page, target_count)

            # ìƒˆë¡œìš´ ê²Œì‹œê¸€ë§Œ ì¶”ê°€
            new_posts_count = 0
            for post_data in current_posts:
                if len(posts) >= target_count:
                    break

                # ì¤‘ë³µ í™•ì¸
                is_duplicate = any(
                    existing.url == post_data.get("url")
                    or (
                        existing.content == post_data.get("content")
                        and existing.author == post_data.get("author")
                    )
                    for existing in posts
                )

                if not is_duplicate and self._is_valid_post(post_data):
                    try:
                        post = Post(platform="linkedin", **post_data)
                        posts.append(post)
                        new_posts_count += 1
                        typer.echo(
                            f"   âœ… ê²Œì‹œê¸€ {len(posts)}: {post_data['author']} - {post_data['content'][:50]}..."
                        )
                    except Exception as e:
                        typer.echo(f"   âš ï¸ ê²Œì‹œê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

            # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
            if len(posts) >= target_count:
                typer.echo(f"âœ… ëª©í‘œ ë‹¬ì„±: {len(posts)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
                break

            # ìƒˆë¡œìš´ ê²Œì‹œê¸€ì´ ì—†ìœ¼ë©´ ìŠ¤í¬ë¡¤
            if new_posts_count == 0:
                await self._scroll_for_more_posts(page)
                scroll_attempts += 1
                await page.wait_for_timeout(self.scroll_delay)

        typer.echo(f"ğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ: {len(posts)}ê°œ ê²Œì‹œê¸€")
        return posts[:target_count]

    async def _expand_all_posts_on_page(self, page: Page):
        """í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ë”ë³´ê¸° ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤"""
        try:
            # ë”ë³´ê¸° ë²„íŠ¼ë“¤ ì°¾ê¸°
            see_more_selectors = [
                ".feed-shared-inline-show-more-text__see-more-less-toggle.see-more",
                'button:has-text("ë”ë³´ê¸°")',
                'button:has-text("â€¦ë”ë³´ê¸°")',
                'button[aria-label*="ë”ë³´ê¸°"]',
                'button:has-text("see more")',
                'button:has-text("...more")',
                ".feed-shared-inline-show-more-text__see-more-less-toggle",
                ".see-more",
            ]

            expanded_count = 0
            for selector in see_more_selectors:
                try:
                    buttons = await page.query_selector_all(selector)
                    for button in buttons:
                        try:
                            if await button.is_visible():
                                await button.scroll_into_view_if_needed()
                                await page.wait_for_timeout(200)
                                await button.click()
                                await page.wait_for_timeout(300)
                                expanded_count += 1
                        except:
                            continue
                except:
                    continue

            if expanded_count > 0:
                typer.echo(f"   ğŸ“– {expanded_count}ê°œ ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")

        except Exception as e:
            typer.echo(f"   âš ï¸ ë”ë³´ê¸° í™•ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _collect_expanded_posts(self, page: Page, target_count: int) -> List[Dict[str, Any]]:
        """í™•ì¥ëœ ê²Œì‹œê¸€ë“¤ì„ ìƒë‹¨ì—ì„œë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤"""
        post_elements = await self._find_post_elements(page)
        posts_data = []

        for i, element in enumerate(post_elements[: target_count * 2]):  # ì—¬ìœ ë¶„ í™•ë³´
            try:
                post_data = await self._extract_post_data_simple(element)
                if post_data:
                    posts_data.append(post_data)
                if len(posts_data) >= target_count:
                    break
            except Exception:
                continue

        return posts_data

    async def _extract_post_data_simple(self, element) -> Optional[Dict[str, Any]]:
        """ë‹¨ìˆœí™”ëœ ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ (ë”ë³´ê¸°ê°€ ì´ë¯¸ í´ë¦­ëœ ìƒíƒœ)"""
        try:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            author = await self._extract_author_progressive(element)
            post_url = await self._extract_post_url_progressive(element)
            timestamp = await self._extract_timestamp_progressive(element)
            content = await self._extract_content_progressive(element)
            interactions = await self._extract_interactions_progressive(element)

            post_data = {
                "author": author,
                "content": content,
                "timestamp": timestamp,
                "url": post_url,
                **interactions,
            }

            return post_data

        except Exception:
            return None

    async def _scroll_for_more_posts(self, page: Page):
        """ë” ë§ì€ ê²Œì‹œê¸€ì„ ë¡œë“œí•˜ê¸° ìœ„í•œ ìŠ¤í¬ë¡¤"""
        try:
            # í˜ì´ì§€ í•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(1000)

            # ì¶”ê°€ ìŠ¤í¬ë¡¤ (LinkedInì˜ ë¬´í•œ ìŠ¤í¬ë¡¤ íŠ¸ë¦¬ê±°)
            await page.evaluate("window.scrollBy(0, 500)")
            await page.wait_for_timeout(1000)

            # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì™„ë£Œ ëŒ€ê¸°
            try:
                await page.wait_for_load_state("networkidle", timeout=5000)
            except PlaywrightTimeoutError:
                pass

        except Exception as e:
            typer.echo(f"   âš ï¸ ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _find_post_elements(self, page: Page) -> List[Any]:
        """ê²Œì‹œê¸€ DOM ìš”ì†Œë“¤ì„ ì°¾ìŠµë‹ˆë‹¤ (ë‹¤ì¤‘ ì„ íƒì ì‹œìŠ¤í…œ)"""
        try:
            # LinkedIn ê²Œì‹œê¸€ ì»¨í…Œì´ë„ˆ ì„ íƒìë“¤
            post_selectors = [
                ".feed-shared-update-v2[data-urn]",
                '[data-id*="urn:li:activity:"]',
                ".feed-shared-update-v2",
                '[data-urn*="update"]',
                "div[data-id]",
                'article[role="article"]',
                ".occludable-update",
                ".scaffold-finite-scroll__content > div > div",
            ]

            post_elements = []
            for selector in post_selectors:
                elements = await page.query_selector_all(selector)
                if elements:
                    for element in elements:
                        if element not in post_elements:
                            if await self._is_valid_post_element(element):
                                post_elements.append(element)
                    break

            # ì¤‘ë³µ ì œê±°
            unique_elements = []
            seen_elements = set()

            for element in post_elements:
                try:
                    element_id = await element.get_attribute(
                        "data-id"
                    ) or await element.get_attribute("data-urn")
                    if not element_id:
                        content = await element.inner_text()
                        element_id = hash(content[:100]) if content else id(element)

                    if element_id not in seen_elements:
                        seen_elements.add(element_id)
                        unique_elements.append(element)
                except:
                    unique_elements.append(element)

            return unique_elements

        except Exception as e:
            typer.echo(f"âš ï¸ ê²Œì‹œê¸€ ìš”ì†Œ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    async def _is_valid_post_element(self, element) -> bool:
        """ê²Œì‹œê¸€ ìš”ì†Œê°€ ìœ íš¨í•œì§€ ê²€ì¦"""
        try:
            # ê²Œì‹œê¸€ì— í•„ìˆ˜ì ì¸ ìš”ì†Œë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
            text_content = await element.inner_text()
            if not text_content or len(text_content.strip()) < 20:
                return False

            # ì‘ì„±ì ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
            author_link = await element.query_selector('a[href*="/in/"], a[href*="/company/"]')
            if not author_link:
                return False

            # ê²Œì‹œê¸€ ì»¨í…ì¸  ì˜ì—­ì´ ìˆëŠ”ì§€ í™•ì¸
            content_area = await element.query_selector(
                ".update-components-text, .break-words, .feed-shared-text"
            )
            if not content_area:
                return False

            return True

        except:
            return False

    async def _extract_author_progressive(self, element) -> str:
        """ì‘ì„±ì ì •ë³´ ì ì§„ì  ì¶”ì¶œ"""
        try:
            # LinkedIn ì‘ì„±ì ë§í¬ ì„ íƒìë“¤ (ì‹¤ì œ HTML êµ¬ì¡° ê¸°ë°˜)
            author_selectors = [
                # ê°œì¸ í”„ë¡œí•„
                '.update-components-actor__meta-link .update-components-actor__title span[dir="ltr"] span[aria-hidden="true"]',
                ".update-components-actor__meta-link .update-components-actor__title span",
                '.update-components-actor__title span[dir="ltr"]',
                'a[href*="/in/"] .update-components-actor__title',
                # íšŒì‚¬ í˜ì´ì§€
                'a[href*="/company/"] span',
                '.update-components-actor__meta-link span[dir="ltr"]',
                # ì¼ë°˜ì ì¸ ì„ íƒì
                'a[href*="/in/"]',
                'a[href*="/company/"]',
                ".feed-shared-actor__name a",
                '[data-control-name="actor"] a',
            ]

            for selector in author_selectors:
                try:
                    author_element = await element.query_selector(selector)
                    if author_element:
                        text = await author_element.inner_text()
                        if text and text.strip() and len(text.strip()) > 1:
                            # ì²« ë²ˆì§¸ ì¤„ë§Œ ê°€ì ¸ì˜¤ê¸° (ì´ë¦„ ë¶€ë¶„)
                            author_name = text.strip().split("\n")[0].strip()
                            if len(author_name) > 1 and not author_name.isdigit():
                                return author_name
                except:
                    continue

            # fallback: hrefì—ì„œ ì¶”ì¶œ
            for selector in ['a[href*="/in/"]', 'a[href*="/company/"]']:
                try:
                    author_link = await element.query_selector(selector)
                    if author_link:
                        href = await author_link.get_attribute("href")
                        if href:
                            if "/in/" in href:
                                username = href.split("/in/")[-1].split("/")[0].split("?")[0]
                            elif "/company/" in href:
                                username = href.split("/company/")[-1].split("/")[0].split("?")[0]
                            else:
                                continue

                            if username and len(username) > 1 and not username.isdigit():
                                return username.replace("-", " ").title()
                except:
                    continue

        except Exception:
            pass

        return "Unknown"

    async def _extract_content_progressive(self, element) -> str:
        """ê²Œì‹œê¸€ ì½˜í…ì¸  ì ì§„ì  ì¶”ì¶œ (ë”ë³´ê¸° í´ë¦­ í›„)"""
        try:
            content_text = ""

            # LinkedIn ê²Œì‹œê¸€ ì½˜í…ì¸  ì„ íƒìë“¤ (í™•ì¥ëœ ìƒíƒœ)
            content_selectors = [
                '.update-components-text .break-words span[dir="ltr"]',
                ".update-components-update-v2__commentary .break-words span",
                '.feed-shared-inline-show-more-text .update-components-text span[dir="ltr"]',
                ".feed-shared-inline-show-more-text .break-words",
                ".update-components-text .break-words",
                ".feed-shared-text",
                ".feed-shared-inline-show-more-text span",
                ".break-words span",
                ".update-components-text",
                '[data-test-id="main-feed-activity-card"] span[dir="ltr"]',
                '[data-control-name="text"] span',
            ]

            for selector in content_selectors:
                try:
                    content_element = await element.query_selector(selector)
                    if content_element:
                        text = await content_element.inner_text()
                        if text and len(text.strip()) > 20:
                            content_text = text.strip()
                            break
                except:
                    continue

            # ëŒ€ì•ˆ: ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ë° ì •ë¦¬
            if not content_text:
                full_text = await element.inner_text()
                if full_text:
                    content_text = self._clean_linkedin_content(full_text)

            # ì—¬ì „íˆ ì½˜í…ì¸ ê°€ ì—†ë‹¤ë©´ ê°œë³„ í…ìŠ¤íŠ¸ ìš”ì†Œë“¤ì„ ì¡°í•©
            if not content_text or len(content_text.strip()) < 20:
                content_text = await self._extract_content_fallback(element)

            return content_text[:1000] if content_text else ""

        except Exception:
            return ""

    async def _extract_content_fallback(self, element) -> str:
        """ì½˜í…ì¸  ì¶”ì¶œ í´ë°± ë°©ë²• (ê°œë³„ í…ìŠ¤íŠ¸ ë…¸ë“œ ì¡°í•©)"""
        try:
            # ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œë“¤ì„ ì°¾ì•„ì„œ ì¡°í•©
            text_elements = await element.query_selector_all("span, p, div")
            content_parts = []

            for text_elem in text_elements:
                try:
                    text = await text_elem.inner_text()
                    if text and len(text.strip()) > 10:
                        # ë²„íŠ¼ì´ë‚˜ UI í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ì‹¤ì œ ì½˜í…ì¸ ë§Œ ì¶”ì¶œ
                        if not any(
                            ui_word in text.lower()
                            for ui_word in [
                                "like",
                                "comment",
                                "share",
                                "follow",
                                "connect",
                                "ì¶”ì²œ",
                                "ëŒ“ê¸€",
                                "í¼ê°€ê¸°",
                                "íŒ”ë¡œìš°",
                                "ì—°ê²°",
                            ]
                        ):
                            content_parts.append(text.strip())

                except:
                    continue

            if content_parts:
                # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
                unique_parts = []
                for part in content_parts:
                    if part not in unique_parts and len(part) > 15:
                        unique_parts.append(part)

                return " ".join(unique_parts[:3])  # ìƒìœ„ 3ê°œ ë¶€ë¶„ë§Œ ì¡°í•©

        except:
            pass

        return ""

    def _clean_linkedin_content(self, content: str) -> str:
        """LinkedIn íŠ¹í™” ì½˜í…ì¸  ì •ë¦¬"""
        if not content:
            return ""

        # LinkedIn íŠ¹í™” ì œì™¸ í‚¤ì›Œë“œ
        exclude_keywords = [
            "like",
            "comment",
            "share",
            "repost",
            "more",
            "ago",
            "ì¶”ì²œ",
            "ëŒ“ê¸€",
            "í¼ê°€ê¸°",
            "ë³´ë‚´ê¸°",
            "ì‹œê°„",
            "ì¼",
            "ë¶„",
            "celebration",
            "love",
            "insightful",
            "curious",
            "íŒ”ë¡œì›Œ",
            "connection",
            "1ì´Œ",
            "2ì´Œ",
            "3ì´Œ",
            "linkedin",
            "í”„ë¡œí•„",
            "follow",
            "connect",
        ]

        # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì¤„ ê²€ì‚¬
        lines = content.split("\n")
        clean_lines = []

        for line in lines:
            line = line.strip()
            if (
                len(line) > 15
                and not any(keyword in line.lower() for keyword in exclude_keywords)
                and not line.isdigit()
                and not all(c in "â€¢Â·-=+*" for c in line.replace(" ", ""))
            ):
                clean_lines.append(line)

        # ì—°ì†ëœ ì¤‘ë³µ ì¤„ ì œê±°
        final_lines = []
        prev_line = ""
        for line in clean_lines:
            if line != prev_line:
                final_lines.append(line)
                prev_line = line

        return "\n".join(final_lines)

    async def _extract_interactions_progressive(self, element) -> Dict[str, Optional[int]]:
        """ìƒí˜¸ì‘ìš© ì •ë³´ ì ì§„ì  ì¶”ì¶œ"""
        interactions: Dict[str, Optional[int]] = {"likes": None, "comments": None, "shares": None}

        try:
            # LinkedIn ìƒí˜¸ì‘ìš© ì¹´ìš´íŠ¸ ì˜ì—­ ì°¾ê¸°
            social_counts = await element.query_selector(".social-details-social-counts")

            if social_counts:
                # ì¢‹ì•„ìš”/ë°˜ì‘ ìˆ˜ ì¶”ì¶œ
                reactions_button = await social_counts.query_selector(
                    "button[data-reaction-details], .social-details-social-counts__reactions"
                )
                if reactions_button:
                    reactions_text = await reactions_button.inner_text()
                    if reactions_text:
                        likes = self._extract_numbers_from_text(reactions_text)
                        if likes > 0:
                            interactions["likes"] = likes

                # ëŒ“ê¸€ ìˆ˜ ì¶”ì¶œ
                comments_button = await social_counts.query_selector(
                    'button[aria-label*="ëŒ“ê¸€"], .social-details-social-counts__comments'
                )
                if comments_button:
                    comments_text = await comments_button.inner_text()
                    if comments_text:
                        comments = self._extract_numbers_from_text(comments_text)
                        if comments > 0:
                            interactions["comments"] = comments

                # ê³µìœ  ìˆ˜ ì¶”ì¶œ (í¼ê°)
                shares_elements = await social_counts.query_selector_all(
                    'button[aria-label*="í¼ê°"], span:has-text("í¼ê°")'
                )
                for elem in shares_elements:
                    shares_text = await elem.inner_text()
                    if shares_text and "í¼ê°" in shares_text:
                        shares = self._extract_numbers_from_text(shares_text)
                        if shares > 0:
                            interactions["shares"] = shares
                            break

            # ëŒ€ì•ˆ: ì•¡ì…˜ ë²„íŠ¼ì—ì„œ ì¶”ì¶œ
            if not any(interactions.values()):
                action_buttons = await element.query_selector_all(
                    ".social-actions-button, .feed-shared-social-action-bar button"
                )

                for button in action_buttons:
                    try:
                        button_text = await button.inner_text()
                        if not button_text:
                            continue

                        button_text_lower = button_text.lower()

                        # ì¢‹ì•„ìš”/ë°˜ì‘ ìˆ˜
                        if any(word in button_text_lower for word in ["like", "ì¶”ì²œ", "reaction"]):
                            likes = self._extract_numbers_from_text(button_text)
                            if likes > 0:
                                interactions["likes"] = likes

                        # ëŒ“ê¸€ ìˆ˜
                        elif "ëŒ“ê¸€" in button_text or "comment" in button_text_lower:
                            comments = self._extract_numbers_from_text(button_text)
                            if comments > 0:
                                interactions["comments"] = comments

                        # ê³µìœ  ìˆ˜
                        elif any(
                            word in button_text_lower for word in ["share", "í¼ê°€ê¸°", "repost"]
                        ):
                            shares = self._extract_numbers_from_text(button_text)
                            if shares > 0:
                                interactions["shares"] = shares

                    except Exception:
                        continue

        except Exception:
            pass

        return interactions

    async def _extract_post_url_progressive(self, element) -> Optional[str]:
        """ê²Œì‹œê¸€ URL ì ì§„ì  ì¶”ì¶œ"""
        try:
            # data-idì—ì„œ URN ì¶”ì¶œ
            data_id = await element.get_attribute("data-id")
            if data_id and "urn:li:activity:" in data_id:
                activity_id = data_id.split("urn:li:activity:")[-1]
                return f"https://www.linkedin.com/feed/update/urn:li:activity:{activity_id}/"

            # data-urnì—ì„œ ì¶”ì¶œ
            data_urn = await element.get_attribute("data-urn")
            if data_urn and "activity:" in data_urn:
                return f"https://www.linkedin.com/feed/update/{data_urn}/"

            # ê²Œì‹œê¸€ ë§í¬ ì§ì ‘ ì°¾ê¸°
            url_selectors = [
                'a[href*="/posts/"]',
                'a[href*="/activity-"]',
                'a[href*="/feed/update/"]',
                '[data-control-name="overlay"] a',
            ]

            for selector in url_selectors:
                post_link = await element.query_selector(selector)
                if post_link:
                    href = await post_link.get_attribute("href")
                    if href and (
                        "/posts/" in href or "/activity-" in href or "/feed/update/" in href
                    ):
                        return (
                            f"https://www.linkedin.com{href}"
                            if not href.startswith("http")
                            else href
                        )

        except Exception:
            pass

        return None

    async def _extract_timestamp_progressive(self, element) -> str:
        """ê²Œì‹œ ì‹œê°„ ì ì§„ì  ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        try:
            # 1ë‹¨ê³„: ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì„ íƒìë¡œ ì§ì ‘ ì¶”ì¶œ
            timestamp_selectors = [
                '.update-components-actor__sub-description span[aria-hidden="true"]',
                ".update-components-actor__sub-description",
                "time",
                ".feed-shared-actor__sub-description time",
                '[data-control-name="actor"] time',
            ]

            for selector in timestamp_selectors:
                try:
                    time_element = await element.query_selector(selector)
                    if time_element:
                        time_text = await time_element.inner_text()
                        if time_text and time_text.strip():
                            # íƒ€ì„ìŠ¤íƒ¬í”„ í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ ì •ë³´ë§Œ ì¶”ì¶œ
                            cleaned_timestamp = self._extract_time_from_text(time_text.strip())
                            if cleaned_timestamp:
                                return cleaned_timestamp
                except:
                    continue

            # 2ë‹¨ê³„: ëŒ€ì•ˆ ê²€ìƒ‰ - ì‹œê°„ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ìš”ì†Œ ì°¾ê¸°
            fallback_selectors = [
                'span:has-text("ì‹œê°„")',
                'span:has-text("ì¼")',
                'span:has-text("ë¶„")',
                'span:has-text("ago")',
                'span:has-text("hour")',
                'span:has-text("day")',
                'span:has-text("week")',
                'span:has-text("ì£¼")',
            ]

            for selector in fallback_selectors:
                try:
                    time_element = await element.query_selector(selector)
                    if time_element:
                        time_text = await time_element.inner_text()
                        if time_text:
                            cleaned_timestamp = self._extract_time_from_text(time_text.strip())
                            if cleaned_timestamp:
                                return cleaned_timestamp
                except:
                    continue

        except Exception:
            pass

        return "ì•Œ ìˆ˜ ì—†ìŒ"

    def _extract_time_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ ì •ë³´ë§Œ ì¶”ì¶œ"""
        if not text:
            return ""

        # ì¤„ë°”ê¿ˆ ì œê±° ë° ì •ë¦¬
        text = text.replace("\n", " ").strip()

        # ì‹œê°„ ê´€ë ¨ íŒ¨í„´ë“¤
        time_patterns = [
            # í•œêµ­ì–´ íŒ¨í„´
            r"(\d+ë¶„\s*[â€¢Â·]?)",
            r"(\d+ì‹œê°„\s*[â€¢Â·]?)",
            r"(\d+ì¼\s*[â€¢Â·]?)",
            r"(\d+ì£¼\s*[â€¢Â·]?)",
            r"(\d+ë‹¬\s*[â€¢Â·]?)",
            r"(\d+ê°œì›”\s*[â€¢Â·]?)",
            r"(\d+ë…„\s*[â€¢Â·]?)",
            # ì˜ì–´ íŒ¨í„´
            r"(\d+\s*minute?s?\s*ago)",
            r"(\d+\s*hour?s?\s*ago)",
            r"(\d+\s*day?s?\s*ago)",
            r"(\d+\s*week?s?\s*ago)",
            r"(\d+\s*month?s?\s*ago)",
            r"(\d+\s*year?s?\s*ago)",
            # ê°„ë‹¨í•œ íŒ¨í„´
            r"(\d+ë¶„)",
            r"(\d+ì‹œê°„)",
            r"(\d+ì¼)",
            r"(\d+ì£¼)",
            r"(\d+ê°œì›”)",
            r"(í˜„ì¬\s*ì‹œê°„)",
            r"(ë‚¨ì€\s*ì‹œê°„)",
        ]

        import re

        # ê° íŒ¨í„´ìœ¼ë¡œ ì‹œê°„ ì •ë³´ ì°¾ê¸°
        for pattern in time_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                time_part = match.group(1).strip()
                # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨ (ìˆ˜ì •ë¨ ë“±)
                if "ìˆ˜ì •ë¨" in text:
                    return f"{time_part} â€¢ ìˆ˜ì •ë¨ â€¢"
                return f"{time_part} â€¢"

        # íŒ¨í„´ì´ ë§¤ì¹˜ë˜ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œ ì‹œê°„ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
        first_sentence = text.split("\n")[0].split(".")[0].strip()

        # ì‹œê°„ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì§§ì€ í…ìŠ¤íŠ¸ë¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        time_keywords = [
            "ë¶„",
            "ì‹œê°„",
            "ì¼",
            "ì£¼",
            "ë‹¬",
            "ê°œì›”",
            "ë…„",
            "ago",
            "minute",
            "hour",
            "day",
            "week",
            "month",
            "year",
            "í˜„ì¬",
            "ë‚¨ì€",
        ]

        if (
            any(keyword in first_sentence.lower() for keyword in time_keywords)
            and len(first_sentence) < 50
        ):
            # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
            cleaned = first_sentence
            # ì•„ì´ì½˜ì´ë‚˜ ê¸°íƒ€ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            unwanted_parts = ["ì›¹ìƒì—ì„œ ëˆ„êµ¬ì—ê²Œë‚˜ ë³´ì„", "ì¸ì¦ë¨", "1ì´Œ", "2ì´Œ", "3ì´Œ", "íŒ”ë¡œì›Œ"]
            for unwanted in unwanted_parts:
                cleaned = cleaned.replace(unwanted, "").strip()

            # ì—°ì†ëœ ê³µë°±ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
            cleaned = re.sub(r"\s+", " ", cleaned)
            cleaned = re.sub(r"[â€¢Â·]{2,}", "â€¢", cleaned)

            if len(cleaned) < 30:  # ì¶©ë¶„íˆ ì§§ìœ¼ë©´ ë°˜í™˜
                return cleaned

        return ""

    async def _load_session(self, page: Page) -> bool:
        """ì €ì¥ëœ ì„¸ì…˜ ìƒíƒœë¥¼ ë¡œë“œí•©ë‹ˆë‹¤"""
        try:
            if self.session_path.exists():
                typer.echo("ğŸ”„ ê¸°ì¡´ ì„¸ì…˜ ë¡œë“œ ì¤‘...")

                # Storage State ë¡œë“œ
                with open(self.session_path, "r") as f:
                    storage_state = json.load(f)

                # ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ì— Storage State ì ìš©
                await page.context.add_cookies(storage_state.get("cookies", []))

                # ë‹¨ê³„ì  í˜ì´ì§€ ë¡œë“œ
                if await self._gradual_page_load(page):
                    # ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
                    if await self._verify_login_status(page):
                        self.is_logged_in = True
                        typer.echo("âœ… ê¸°ì¡´ ì„¸ì…˜ìœ¼ë¡œ ë¡œê·¸ì¸ ì„±ê³µ!")
                        return True
                    else:
                        typer.echo("âš ï¸ ê¸°ì¡´ ì„¸ì…˜ì´ ë§Œë£Œë¨")
                        if self.session_path.exists():
                            self.session_path.unlink()
                        return False
                else:
                    typer.echo("âš ï¸ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨ - ì„¸ì…˜ ë¬´íš¨í™”")
                    if self.session_path.exists():
                        self.session_path.unlink()
                    return False
            else:
                return False

        except Exception as e:
            typer.echo(f"âš ï¸ ì„¸ì…˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            if self.session_path.exists():
                self.session_path.unlink()
            return False

    async def _gradual_page_load(self, page: Page) -> bool:
        """LinkedInì— ìµœì í™”ëœ ë‹¨ê³„ì  í˜ì´ì§€ ë¡œë“œ"""
        try:
            # ê¸°ë³¸ í˜ì´ì§€ ë¡œë“œ
            try:
                await page.goto(
                    self.base_url,
                    wait_until="domcontentloaded",
                    timeout=15000,
                )
            except PlaywrightTimeoutError:
                pass

            # í˜ì´ì§€ ì•ˆì •í™” ëŒ€ê¸°
            await page.wait_for_timeout(2000)

            # LinkedIn íŠ¹ì • ìš”ì†Œ ëŒ€ê¸°
            try:
                await page.wait_for_selector(
                    'header, .global-nav, .feed-container, [data-test-id="nav-top"]', timeout=10000
                )
            except PlaywrightTimeoutError:
                pass

            # ì¶”ê°€ JavaScript ì‹¤í–‰ ëŒ€ê¸°
            try:
                await page.wait_for_load_state("load", timeout=5000)
            except PlaywrightTimeoutError:
                pass

            # ìµœì¢… í™•ì¸
            current_url = page.url
            return "linkedin.com" in current_url

        except Exception:
            return False

    async def _verify_login_status(self, page: Page) -> bool:
        """ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸"""
        try:
            # URL í™•ì¸
            current_url = page.url
            if "/login" in current_url or "/uas/login" in current_url:
                return False

            # í”¼ë“œ íŠ¹ì • ìš”ì†Œ í™•ì¸
            post_composer = await page.query_selector('button[aria-label*="Start a post"]')
            if post_composer:
                return True

            # í”¼ë“œ ê²Œì‹œê¸€ í™•ì¸
            feed_posts = await page.query_selector_all(
                '.feed-shared-update-v2, [data-urn*="update"]'
            )
            if len(feed_posts) > 0:
                return True

            # í”„ë¡œí•„ ë©”ë‰´ í™•ì¸
            profile_menu = await page.query_selector(
                '[data-control-name="identity_welcome_message"]'
            )
            if profile_menu:
                return True

            return False

        except Exception:
            return False

    async def _attempt_login(self, page: Page) -> bool:
        """LinkedIn ê³„ì • ë¡œê·¸ì¸ ì‹œë„"""
        if not self.username or not self.password:
            typer.echo("âš ï¸ í™˜ê²½ ë³€ìˆ˜ì— ê³„ì • ì •ë³´ê°€ ì—†ìŒ (.env íŒŒì¼ í™•ì¸ í•„ìš”)")
            self.username = typer.prompt("LinkedIn ì‚¬ìš©ìëª… (ì´ë©”ì¼)")
            self.password = typer.prompt("LinkedIn ë¹„ë°€ë²ˆí˜¸", hide_input=True)

        for attempt in range(self.login_retry_count):
            try:
                typer.echo(f"ğŸ” ë¡œê·¸ì¸ ì‹œë„ {attempt + 1}/{self.login_retry_count}")

                # ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™
                current_url = page.url
                if "/uas/login" not in current_url and "/checkpoint" not in current_url:
                    await page.goto("https://www.linkedin.com/login", wait_until="networkidle")

                # ë¡œê·¸ì¸ í¼ ëŒ€ê¸°
                await page.wait_for_selector(
                    'input[name="session_key"]', timeout=self.login_timeout
                )

                # ì‚¬ìš©ìëª… ì…ë ¥
                username_input = await page.query_selector('input[name="session_key"]')
                if username_input:
                    await username_input.click()
                    await username_input.fill("")
                    await page.wait_for_timeout(300)
                    for char in self.username:
                        await username_input.type(char, delay=random.randint(50, 150))

                # ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
                password_input = await page.query_selector('input[name="session_password"]')
                if password_input:
                    await password_input.click()
                    await password_input.fill("")
                    await page.wait_for_timeout(300)
                    for char in self.password:
                        await password_input.type(char, delay=random.randint(50, 120))

                # ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­
                await page.wait_for_timeout(random.randint(1000, 2000))
                submit_button = await page.query_selector('button[type="submit"]')
                if submit_button:
                    await submit_button.click()

                    try:
                        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
                        await page.wait_for_load_state("networkidle", timeout=15000)
                        # LinkedIn í”¼ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ ëŒ€ê¸°
                        await page.wait_for_url("**/feed/**", timeout=10000)
                    except PlaywrightTimeoutError:
                        pass

                # ë³´ì•ˆ í™•ì¸ ë‹¨ê³„ ì²˜ë¦¬
                await self._handle_security_challenges(page)

                # ë¡œê·¸ì¸ ì„±ê³µ í™•ì¸
                await page.wait_for_timeout(3000)
                if await self._verify_login_status(page):
                    typer.echo("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")
                    self.is_logged_in = True
                    await self._save_session(page)
                    return True
                else:
                    if attempt < self.login_retry_count - 1:
                        await page.wait_for_timeout(random.randint(3000, 5000))

            except PlaywrightTimeoutError:
                if attempt < self.login_retry_count - 1:
                    await page.wait_for_timeout(random.randint(2000, 4000))
            except Exception as e:
                typer.echo(f"   âŒ ë¡œê·¸ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
                if attempt < self.login_retry_count - 1:
                    await page.wait_for_timeout(random.randint(2000, 4000))

        typer.echo(f"âŒ {self.login_retry_count}ë²ˆ ì‹œë„ í›„ ë¡œê·¸ì¸ ì‹¤íŒ¨")
        return False

    async def _handle_security_challenges(self, page: Page) -> None:
        """ë³´ì•ˆ í™•ì¸ ë‹¨ê³„ ì²˜ë¦¬"""
        try:
            await page.wait_for_timeout(2000)

            # ì´ë©”ì¼ ì¸ì¦ ì½”ë“œ ì…ë ¥ í™”ë©´
            verification_input = await page.query_selector('input[name="pin"]')
            if verification_input:
                typer.echo("ğŸ” ì´ë©”ì¼ ì¸ì¦ ì½”ë“œ ì…ë ¥ í•„ìš”")
                verification_code = typer.prompt("LinkedIn ì¸ì¦ ì½”ë“œ ì…ë ¥")

                await verification_input.click()
                await verification_input.fill(verification_code)

                submit_button = await page.query_selector('button[type="submit"]')
                if submit_button:
                    await submit_button.click()
                    await page.wait_for_timeout(3000)

            # "Trust this browser" í™”ë©´
            trust_button = await page.query_selector('button:has-text("Trust this browser")')
            if trust_button:
                await trust_button.click()
                await page.wait_for_timeout(2000)

        except Exception as e:
            typer.echo(f"âš ï¸ ë³´ì•ˆ í™•ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def _is_valid_post(self, post_data: Dict[str, Any]) -> bool:
        """ê²Œì‹œê¸€ ë°ì´í„°ê°€ ìœ íš¨í•œì§€ í™•ì¸"""
        content = post_data.get("content")
        author = post_data.get("author")

        return bool(
            content and len(str(content).strip()) > 15 and author and str(author) != "Unknown"
        )

    async def _save_session(self, page: Page) -> bool:
        """í˜„ì¬ ì„¸ì…˜ ìƒíƒœë¥¼ Storage Stateë¡œ ì €ì¥í•©ë‹ˆë‹¤"""
        try:
            # Storage State ì¶”ì¶œ
            storage_state = await page.context.storage_state()

            # ì„¸ì…˜ íŒŒì¼ì— ì €ì¥
            with open(self.session_path, "w") as f:
                json.dump(storage_state, f, indent=2)

            typer.echo(f"ğŸ’¾ ì„¸ì…˜ì´ ì €ì¥ë¨")
            return True

        except Exception as e:
            typer.echo(f"âš ï¸ ì„¸ì…˜ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

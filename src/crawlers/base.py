"""
@file base.py
@description SNS í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤

ì´ ëª¨ë“ˆì€ ëª¨ë“  SNS í”Œë«í¼ í¬ë¡¤ëŸ¬ì˜ ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ê³µí†µ í¬ë¡¤ë§ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
2. Playwright ë¸Œë¼ìš°ì € ê´€ë¦¬
3. ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œê¹…
4. í¬ë¡¤ë§ ê²°ê³¼ ê²€ì¦

í•µì‹¬ êµ¬í˜„ ë¡œì§:
- ABC(Abstract Base Class)ë¥¼ ì‚¬ìš©í•œ ì¸í„°í˜ì´ìŠ¤ ê°•ì œ
- Playwright async context manager íŒ¨í„´
- í”Œë«í¼ë³„ User-Agent ì„¤ì •
- í¬ë¡¤ë§ ì§„í–‰ ìƒí™© í‘œì‹œ

@dependencies
- abc: ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
- playwright.async_api: ë¸Œë¼ìš°ì € ìë™í™”
- typer: CLI ì¶œë ¥

@see {@link /docs/crawler-architecture.md} - í¬ë¡¤ëŸ¬ ì•„í‚¤í…ì²˜ ë¬¸ì„œ
"""

from abc import ABC, abstractmethod
from typing import List, Optional

import typer
from playwright.async_api import Browser, BrowserContext, Page, async_playwright

from ..models import Post


class BaseCrawler(ABC):
    """
    SNS í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤

    ëª¨ë“  í”Œë«í¼ë³„ í¬ë¡¤ëŸ¬ê°€ ìƒì†í•´ì•¼ í•˜ëŠ” ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ê³µí†µ ë¸Œë¼ìš°ì € ê´€ë¦¬ ê¸°ëŠ¥ê³¼ í¬ë¡¤ë§ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, platform_name: str, base_url: str, user_agent: Optional[str] = None):
        """
        ë² ì´ìŠ¤ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”

        Args:
            platform_name (str): í”Œë«í¼ ì´ë¦„ (ì˜ˆ: threads, linkedin)
            base_url (str): í”Œë«í¼ ê¸°ë³¸ URL
            user_agent (Optional[str]): ì‚¬ìš©í•  User-Agent ë¬¸ìì—´
        """
        self.platform_name = platform_name
        self.base_url = base_url
        self.user_agent = user_agent or self._get_default_user_agent()

    def _get_default_user_agent(self) -> str:
        """í”Œë«í¼ë³„ ê¸°ë³¸ User-Agent ë°˜í™˜"""
        return "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

    async def crawl(self, count: int = 5) -> List[Post]:
        """
        ë©”ì¸ í¬ë¡¤ë§ ì‹¤í–‰ í•¨ìˆ˜

        Args:
            count (int): ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜

        Returns:
            List[Post]: í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ ëª©ë¡
        """
        posts = []

        try:
            typer.echo(f"ğŸ”„ {self.platform_name} í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=False)

                context = await browser.new_context(user_agent=self.user_agent)
                page = await context.new_page()

                try:
                    posts = await self._crawl_implementation(page, count)
                finally:
                    await browser.close()

            typer.echo(f"ğŸ“Š ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

            if not posts:
                typer.echo(f"âŒ ê²Œì‹œê¸€ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                typer.echo(f"ğŸ’¡ íŒíŠ¸: {self.platform_name}ì€(ëŠ”) ë¡œê·¸ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            typer.echo(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return posts

    @abstractmethod
    async def _crawl_implementation(self, page: Page, count: int) -> List[Post]:
        """
        í”Œë«í¼ë³„ êµ¬ì²´ì ì¸ í¬ë¡¤ë§ êµ¬í˜„ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„ í•„ìˆ˜)

        Args:
            page (Page): Playwright í˜ì´ì§€ ê°ì²´
            count (int): ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜

        Returns:
            List[Post]: í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ ëª©ë¡
        """
        pass

    def _extract_numbers_from_text(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì¢‹ì•„ìš”, ëŒ“ê¸€ ìˆ˜ ë“±)"""
        numbers = "".join(filter(str.isdigit, text))
        return int(numbers) if numbers else 0

    def _clean_content(self, content: str, exclude_keywords: Optional[List[str]] = None) -> str:
        """
        ì½˜í…ì¸  í…ìŠ¤íŠ¸ ì •ë¦¬

        Args:
            content (str): ì›ë³¸ ì½˜í…ì¸ 
            exclude_keywords (Optional[List[str]]): ì œì™¸í•  í‚¤ì›Œë“œ ëª©ë¡

        Returns:
            str: ì •ë¦¬ëœ ì½˜í…ì¸ 
        """
        if not content:
            return ""

        if exclude_keywords is None:
            exclude_keywords = ["like", "comment", "share", "repost", "more", "ago"]

        # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì¤„ ê²€ì‚¬
        lines = content.split("\n")
        clean_lines = []

        for line in lines:
            line = line.strip()
            if (
                len(line) > 10
                and not any(keyword in line.lower() for keyword in exclude_keywords)
                and not line.isdigit()
            ):
                clean_lines.append(line)

        return "\n".join(clean_lines)[:500]  # ê¸¸ì´ ì œí•œ

"""
@file base.py
@description SNS í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤

ì´ ëª¨ë“ˆì€ ëª¨ë“  SNS í”Œë«í¼ í¬ë¡¤ëŸ¬ì˜ ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ê³µí†µ í¬ë¡¤ë§ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
2. Playwright ë¸Œë¼ìš°ì € ê´€ë¦¬
3. ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œê¹…
4. í¬ë¡¤ë§ ê²°ê³¼ ê²€ì¦

í•µì‹¬ êµ¬í˜„ ë¡œì§:
- ABC(Abstract Base Class)ë¥¼ ì‚¬ìš©í•œ ì¸í„°í˜ì´ìŠ¤ ê°•ì œ
- Playwright async context manager íŒ¨í„´
- í”Œë«í¼ë³„ User-Agent ì„¤ì •
- í¬ë¡¤ë§ ì§„í–‰ ìƒí™© í‘œì‹œ

@dependencies
- abc: ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
- playwright.async_api: ë¸Œë¼ìš°ì € ìë™í™”
- typer: CLI ì¶œë ¥

@see {@link /docs/crawler-architecture.md} - í¬ë¡¤ëŸ¬ ì•„í‚¤í…ì²˜ ë¬¸ì„œ
"""

import asyncio
import re
from abc import ABC, abstractmethod
from typing import List, Optional

import typer
from playwright.async_api import Browser, BrowserContext, Page, async_playwright

from ..models import Post


class BaseCrawler(ABC):
    """
    SNS í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤

    ëª¨ë“  í”Œë«í¼ë³„ í¬ë¡¤ëŸ¬ê°€ ìƒì†í•´ì•¼ í•˜ëŠ” ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ê³µí†µ ë¸Œë¼ìš°ì € ê´€ë¦¬ ê¸°ëŠ¥ê³¼ í¬ë¡¤ë§ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        platform_name: str,
        base_url: str,
        user_agent: Optional[str] = None,
        debug_mode: bool = False,
    ):
        """
        ë² ì´ìŠ¤ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”

        Args:
            platform_name (str): í”Œë«í¼ ì´ë¦„ (ì˜ˆ: threads, linkedin)
            base_url (str): í”Œë«í¼ ê¸°ë³¸ URL
            user_agent (Optional[str]): ì‚¬ìš©í•  User-Agent ë¬¸ìì—´
            debug_mode (bool): ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
        """
        self.platform_name = platform_name
        self.base_url = base_url
        self.user_agent = user_agent or self._get_default_user_agent()
        self.debug_mode = debug_mode

    def _get_default_user_agent(self) -> str:
        """í”Œë«í¼ë³„ ê¸°ë³¸ User-Agent ë°˜í™˜"""
        return "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

    async def crawl(self, count: int = 5) -> List[Post]:
        """
        ë©”ì¸ í¬ë¡¤ë§ ì‹¤í–‰ í•¨ìˆ˜

        Args:
            count (int): ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜

        Returns:
            List[Post]: í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ ëª©ë¡
        """
        posts = []

        try:
            if self.debug_mode:
                typer.echo(
                    f"ğŸ› ë””ë²„ê·¸ ëª¨ë“œë¡œ {self.platform_name} í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)"
                )
                typer.echo("   - ë¸Œë¼ìš°ì € ì°½ì´ í‘œì‹œë©ë‹ˆë‹¤")
            else:
                typer.echo(f"ğŸ”„ {self.platform_name} í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²Œì‹œê¸€ {count}ê°œ)")

            async with async_playwright() as p:
                # í•­ìƒ ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ (ì¼ë°˜ ëª¨ë“œ, ë””ë²„ê·¸ ëª¨ë“œ ëª¨ë‘)
                browser = await p.chromium.launch(
                    headless=False,  # í•­ìƒ ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ
                    devtools=self.debug_mode,  # ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ê°œë°œì ë„êµ¬ ì—´ê¸°
                )

                context = await browser.new_context(user_agent=self.user_agent)
                page = await context.new_page()

                try:
                    posts = await self._crawl_implementation(page, count)
                finally:
                    if self.debug_mode:
                        typer.echo(
                            "ğŸ› ë””ë²„ê·¸ ëª¨ë“œ: ë¸Œë¼ìš°ì €ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë‹«ìœ¼ì„¸ìš” (ì™„ë£Œ í›„ Enterë¥¼ ëˆ„ë¥´ë©´ ìë™ ì¢…ë£Œ)"
                        )
                        try:
                            # ì‚¬ìš©ìê°€ Enterë¥¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸° (5ë¶„ íƒ€ì„ì•„ì›ƒ)
                            await asyncio.wait_for(asyncio.to_thread(input), timeout=300)
                        except asyncio.TimeoutError:
                            typer.echo("â° 5ë¶„ íƒ€ì„ì•„ì›ƒ - ë¸Œë¼ìš°ì €ë¥¼ ìë™ìœ¼ë¡œ ë‹«ìŠµë‹ˆë‹¤")
                        except:
                            pass
                    await browser.close()

            typer.echo(f"ğŸ“Š ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

            if not posts:
                typer.echo(f"âŒ ê²Œì‹œê¸€ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                if self.debug_mode:
                    typer.echo(f"ğŸ’¡ ë””ë²„ê·¸ íŒíŠ¸:")
                    typer.echo(f"   - ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”")
                    typer.echo(f"   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ ì ê²€í•˜ì„¸ìš”")
                    typer.echo(f"   - í”Œë«í¼ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”")
                else:
                    typer.echo(f"ğŸ’¡ íŒíŠ¸: {self.platform_name}ì€(ëŠ”) ë¡œê·¸ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    typer.echo(f"   ë””ë²„ê·¸ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”: --debug")

        except Exception as e:
            typer.echo(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if self.debug_mode:
                typer.echo(f"ğŸ› ë””ë²„ê·¸ ì •ë³´: {e}")

        return posts

    @abstractmethod
    async def _crawl_implementation(self, page: Page, count: int) -> List[Post]:
        """
        í”Œë«í¼ë³„ êµ¬ì²´ì ì¸ í¬ë¡¤ë§ êµ¬í˜„ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„ í•„ìˆ˜)

        Args:
            page (Page): Playwright í˜ì´ì§€ ê°ì²´
            count (int): ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜

        Returns:
            List[Post]: í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ ëª©ë¡
        """
        pass

    def _extract_numbers_from_text(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ (K, M ë‹¨ìœ„ ì§€ì›)"""
        text = text.lower().replace(",", "")
        m = re.search(r"(\d+(?:\.\d+)?)([kKmM]?)", text)
        if not m:
            return 0
        value, suffix = m.groups()
        num = float(value)
        if suffix == "k":
            num *= 1_000
        elif suffix == "m":
            num *= 1_000_000
        return int(num)

    def _clean_content(self, content: str, exclude_keywords: Optional[List[str]] = None) -> str:
        """
        ì½˜í…ì¸  í…ìŠ¤íŠ¸ ì •ë¦¬

        Args:
            content (str): ì›ë³¸ ì½˜í…ì¸ 
            exclude_keywords (Optional[List[str]]): ì œì™¸í•  í‚¤ì›Œë“œ ëª©ë¡

        Returns:
            str: ì •ë¦¬ëœ ì½˜í…ì¸ 
        """
        if not content:
            return ""

        if exclude_keywords is None:
            exclude_keywords = ["like", "comment", "share", "repost", "more", "ago"]

        # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì¤„ ê²€ì‚¬
        lines = content.split("\n")
        clean_lines = []

        for line in lines:
            line = line.strip()
            if (
                len(line) > 10
                and not any(keyword in line.lower() for keyword in exclude_keywords)
                and not line.isdigit()
            ):
                clean_lines.append(line)

        return "\n".join(clean_lines)[:500]  # ê¸¸ì´ ì œí•œ
